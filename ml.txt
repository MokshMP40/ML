import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.datasets import load_iris
iris = load_iris()
iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)
iris_df['target'] = iris.target
plt.figure(figsize=(8, 6))
plt.scatter(iris_df['sepal length (cm)'], iris_df['sepal width (cm)'], 
            c=iris_df['target'], cmap='viridis', s=80, alpha=0.6)
plt.xlabel("Sepal Length (cm)")
plt.ylabel("Sepal Width (cm)")
plt.title("Scatter Plot of Sepal Length vs Sepal Width")
plt.colorbar(label="Species")
plt.show()
plt.figure(figsize=(8, 6))
sns.countplot(x='target', data=iris_df, palette='viridis')
plt.xlabel("Species")
plt.ylabel("Count")
plt.title("Bar Chart: Count of Each Species")
plt.show()
5



from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
iris = load_iris()
X = iris.data
y = iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
k = 3
knn_classifier = KNeighborsClassifier(n_neighbors=k)
knn_classifier.fit(X_train, y_train)
predictions = knn_classifier.predict(X_test)
accuracy = metrics.accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy}")
print("Classification Report:")
print(metrics.classification_report(y_test, predictions))
print("Confusion Matrix:")
print(metrics.confusion_matrix(y_test, predictions))
7



import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
X, _ = make_blobs(n_samples=300, centers=4, cluster_std=1.0, random_state=42)
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(X)
cluster_labels = kmeans.predict(X)
plt.figure(figsize=(7, 5))
plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='viridis', edgecolors='k')
plt.scatter(
    kmeans.cluster_centers_[:, 0], 
    kmeans.cluster_centers_[:, 1], 
    marker='o', s=200, color='red', label='Centroid')
plt.title('K-Means Clustering')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.show()
10






from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt
iris = load_iris()
X = iris.data
y = iris.target
class_names = [str(name) for name in iris.target_names]
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X, y)
plt.figure(figsize=(12, 8))
plot_tree(decision_tree, feature_names=iris.feature_names, class_names=class_names, filled=True, rounded=True)
plt.title("Decision Tree Visualization")
plt.show()
9




from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
X, y = make_regression(n_samples=1000, n_features=1, noise=20, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)
predictions = linear_reg.predict(X_test)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)
print("Mean Squared Error (MSE):", mse)
print("R-square:", r2)
plt.scatter(X_test, y_test, color="blue")
plt.plot(X_test, predictions, color="red", linewidth=3)
plt.xlabel("X")
plt.ylabel("Y")
plt.title("Linear Regression")
plt.show()
8
 




import pandas as pd
from sklearn.impute import SimpleImputer
data = {'Age': [25, 20, None, 35, 40],'Salary': [50000, None, 65000, 70000, 80000]  # Fixed '8000077' to '80000'}
df = pd.DataFrame(data)
print("Data Frame before imputing missing values using mean:\n", df)
imputer = SimpleImputer(strategy='mean')
df[['Age', 'Salary']] = imputer.fit_transform(df[['Age', 'Salary']])
print("\nData Frame after imputing missing values using mean:\n", df)
6a




import pandas as pd
from sklearn.impute import SimpleImputer
data = {'Age': [25, 30, None, 35, 40],'Salary': [50000, None, 65000, 70000, 80000]}
df = pd.DataFrame(data)
print("Data Frame before forward fill method:\n", df)
df.fillna(method='ffill', inplace=True)
print("\nData Frame after forward fill method:\n", df)
6b



import pandas as pd  
data = {'Age': [25, None, 35, 40],'Salary': [50000, None, 65000, 70000]}  
df = pd.DataFrame(data)  
print("Data Frame before backward fill method:\n", df)  
df.fillna(method='bfill', inplace=True)  
print("\nData Frame after backward fill method:\n", df)
6c




import pandas as pd  
from sklearn.preprocessing import OneHotEncoder  
data = {'City': ['Mandya', 'Bengaluru', 'India', 'Durga', 'Jalandhar', 'Tumakuru']}  
df = pd.DataFrame(data)  
print("Data Frame before One Hot Encoding:\n", df)  
encoder = OneHotEncoder(sparse_output=False)  
encoded = encoder.fit_transform(df[['City']])  
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['City']))  
print("\nData Frame after One Hot Encoding:\n", encoded_df)
6d




import pandas as pd  
from sklearn.preprocessing import LabelEncoder  
df = pd.DataFrame({'Gender': ['Male', 'Female', 'Female', 'Male', 'Female']})  
print("Data Frame before Label Encoding:\n", df)  
encoder = LabelEncoder()  
df['Gender'] = encoder.fit_transform(df['Gender'])  
print("\nData Frame after Label Encoding:\n", df)
6e




import pandas as pd  
from sklearn.preprocessing import StandardScaler  
data = {'Age': [25, 30, 35, 40, 45],'Salary': [50000, 60000, 65000, 70000, 36000]}  
df = pd.DataFrame(data)  
print("Feature Scaling DF before standardization:\n", df)  
scaler = StandardScaler()  
df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)  
print("\nFeature Scaling DF after standardization:\n", df_scaled)
6f



import pandas as pd  
from sklearn.preprocessing import MinMaxScaler  
data = {'Age': [25, 30, 35, 40, 45],'Salary': [50000, 60000, 65000, 70000, 36000]}  
df = pd.DataFrame(data)  
print("Feature Scaling DF before Min-Max Scaling:\n", df)  
scaler = MinMaxScaler()  
df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)  
print("\nFeature Scaling DF after Min-Max Scaling:\n", df_scaled)
6g
